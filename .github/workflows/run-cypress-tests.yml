name: Trigger End-to-end Tests Workflow

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to run tests against (production/staging)'
        default: staging
        required: true
      grep:
        description: 'Grep pattern for selecting tests'
        required: false
        default: ''
      grepTags:
        description: 'Grep tags for selecting tests'
        required: false
        default: '@essential'

  workflow_call:
    inputs:
      environment:
        description: 'Environment to run tests against'
        required: true
        type: string
      grep:
        description: 'Grep pattern for selecting tests'
        required: false
        type: string
      grepTags:
        description: 'Grep tags for selecting tests'
        required: false
        type: string
        default: '@essential'

    secrets:
      DOCKER_PAT:
        required: true
      CYPRESS_PASSWORD:
        required: true
      S3_ACCESS_KEY_ID:
        required: true
      S3_SECRET_ACCESS_KEY:
        required: true
      STAGING_SERVER_IP:
        required: true
      AWS_PRIVATE_KEY_UBUNTU_USER:
        required: true
      SENDGRID_API_KEY:
        required: true


jobs:
  built-and-run-cypress:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create Docker network
        run: docker network create footlight-network.test

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.S3_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          aws-region: ca-central-1

      - name: Run mongodb with latest dump
        env:
          BUCKET_NAME: footlight-dump
        run: |
          docker run -d --name test.mongo --network footlight-network.test -p 27017:27017 mongo:latest

          latest_file=$(aws s3 ls s3://$BUCKET_NAME/ --recursive | sort | tail -n 1 | awk '{print $4}')
          aws s3 cp s3://$BUCKET_NAME/$latest_file ./latest_file.zip
          unzip latest_file.zip -d ./latest_file

          docker cp ./latest_file test.mongo:/dump
          docker exec test.mongo mongorestore --db footlight-calendar /dump/$latest_file/footlight-calendar

      - name: Import dev users to test database
        env:
          PRIVATE_KEY: ${{ secrets.AWS_PRIVATE_KEY_UBUNTU_USER  }}
          STAGING_IP: ${{ secrets.STAGING_SERVER_IP }}
        run: |
          sudo apt install python3-pymongo
          echo "$PRIVATE_KEY" > private_key && chmod 600 private_key
          scp -o StrictHostKeyChecking=no -i private_key ubuntu@${STAGING_IP}:application/scripts/add-dev-users.py .
          python3 add-dev-users.py --mongo_uri "mongodb://localhost:27017/"
        
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ vars.USERNAME_DEV }}
          password: ${{ secrets.DOCKER_PAT }}

      - name: Create env file
        run: |
          echo "APP_PORT=8080" >> .env
          echo "DATABASE_URL=mongodb://test.mongo:27017/footlight-calendar" >> .env
          echo "AWS_S3_ACCESS_KEY_ID=${{ secrets.S3_ACCESS_KEY_ID }}"  >> .env  
          echo "AWS_S3_SECRET_ACCESS_KEY=${{ secrets.S3_SECRET_ACCESS_KEY}}" >> .env     
          echo "DEFAULT_TIMEZONE=Canada/Eastern" >> .env  
          echo "AWS_S3_BUCKET=${{vars.AWS_S3_BUCKET}}" >> .env
          echo "AWS_S3_REGION=${{vars.AWS_S3_REGION}}" >> .env

      - name: Pull and Run CMS Backend Docker Image
        run: |
          if [ "${{ inputs.environment }}" == "production" ]; then
            IMAGE="ghcr.io/culturecreates/footlight-calendar-api/footlight-admin-api:master"
          elif [ "${{ inputs.environment }}" == "staging" ]; then
            IMAGE="ghcr.io/culturecreates/footlight-calendar-api/footlight-admin-api:develop"
          fi
          
          docker pull $IMAGE
      
          docker run -d \
            --restart always \
            --name test.footlight.api \
            --network footlight-network.test \
            -p 8080:8080 \
            $IMAGE

          docker cp ./.env test.footlight.api:/usr/src/app

      - name: Build and run Footlight Container
        run: |
          sed -i 's|^REACT_APP_API_URL=.*|REACT_APP_API_URL="http://test.footlight.api:8080"|' .env.staging
          docker build -t footlight .
          docker run -d --name test.footlight.app --network footlight-network.test -p 3000:3000 footlight

      - name: Wait for Footlight to be ready
        run: |
          for i in {1..5}; do
            if curl -s http://localhost:3000; then
              echo "Footlight is up and running!"
              exit 0
            fi
            echo "Waiting for Footlight to be ready..."
            sleep 10
          done
          echo "Footlight did not start in time!"
          exit 1   

      - name: Checking for migrations on test database
        run: |
          docker exec test.footlight.api npm run migrate:up

      - name: Pull cypress docker image
        run: docker pull ghcr.io/kmdvs/cms-cypress_regression_tests:main

      - name: Run Cypress tests
        run: |

          grep_value="${{ inputs.grep }}"
          echo "Original grep_value: '$grep_value'"
          grep_value_clean=$(echo "$grep_value" | tr -d '\n\r')
          echo "Cleaned grep_value: '$grep_value_clean'"

          if [ -z "$grep_value_clean" ]; then
            grep_value_json='""'
          else
            grep_value_json=$(printf '%s' "$grep_value_clean" | sed 's/"/\\"/g; s/.*/"&"/')
          fi
          echo "JSON grep_value: '$grep_value_json'"
          
          # Properly format the --env argument for Cypress
          env_json="{\"grepTags\":\"${{ inputs.grepTags }}\",\"grep\":${grep_value_json}}"
          echo "Formatted env JSON: $env_json"
          
          # Simulate the Cypress --env argument
          env_arg=$(printf '%s' "$env_json")
          echo "Simulated --env argument for Cypress: $env_arg"
          
          # Validate JSON formatting
          echo "$env_json" | jq . # Validate JSON formatting

          base_url="http://test.footlight.app:3000/"

          # Run Cypress tests with the formatted --env argument
          docker run \
          --network footlight-network.test \
          -e DEBUG="" \
          -e XDG_RUNTIME_DIR=/tmp/runtime \
          -e CYPRESS_BASE_URL=$base_url \
          -e CYPRESS_PRINT_LOGS_TO_CONSOLE="never" \
          -e CYPRESS_ADMIN_EN_PASSWORD=${{ secrets.CYPRESS_PASSWORD }} \
          -e CYPRESS_ADMIN_FR_PASSWORD=${{ secrets.CYPRESS_PASSWORD }} \
          -e CYPRESS_GUEST_EN_PASSWORD=${{ secrets.CYPRESS_PASSWORD }} \
          -e CYPRESS_GUEST_FR_PASSWORD=${{ secrets.CYPRESS_PASSWORD }} \
          -e HEADLESS="true" \
          -v ${GITHUB_WORKSPACE}/cypress/screenshots:/e2e/cypress/screenshots \
          -v ${GITHUB_WORKSPACE}/cypress/videos:/e2e/cypress/videos \
          -v ${GITHUB_WORKSPACE}/cypress/logs:/e2e/cypress/logs \
          ghcr.io/kmdvs/cms-cypress_regression_tests:main \
          npx cypress run --browser firefox --env "$env_arg"

      - name: Upload Cypress Debug Logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cypress-debug-logs
          path: cypress/logs/debug-firefox.log

      - name: Upload Cypress Screenshots
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cypress-screenshots-firefox
          path: cypress/screenshots
          if-no-files-found: ignore

      - name: Upload Cypress Videos
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cypress-videos-firefox
          path: cypress/videos
          if-no-files-found: ignore

  send-failure-notification:
    runs-on: ubuntu-latest
    needs: built-and-run-cypress
    if: failure()
    steps:
      - uses: licenseware/send-email-notification@v1
        with:
          api-key: ${{ secrets.SENDGRID_API_KEY }}
          subject: "Medium Alert - ${{github.repository}} [${{github.workflow}}]"
          from-email: ${{ vars.SENDGRID_FROM_EMAIL }}
          to-email: ${{ vars.MEDIUM_ALERTS_EMAIL }}
          markdown-body: ${{github.workflow}} in ${{github.repository}} failed.